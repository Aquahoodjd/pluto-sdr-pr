{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Synchronization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "try:\n",
    "    import cupy as cp\n",
    "    NO_CUPY = False\n",
    "except ImportError:\n",
    "    warnings.warn(\"CuPy is not installed (needed for GPU acceleration). Falling back to CPU, which might be extremly slow!\")\n",
    "    NO_CUPY = True\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import rtl_sdr_pr.ioutils\n",
    "import rtl_sdr_pr.processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIR-based sub-sample Synchronization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frac_delay_fir(ntaps, u):\n",
    "    if u % 1 == 0:\n",
    "        u += np.finfo(float).eps\n",
    "    \n",
    "    N = ntaps - 1\n",
    "    n = np.linspace(-N/2, N/2, ntaps)\n",
    "    win = signal.chebwin(ntaps, 70)\n",
    "    return np.multiply(np.sinc(n - u), win.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = np.hanning(7)/4\n",
    "x = np.convolve(win, np.ones(20))\n",
    "b_zero = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "y1 = np.convolve(b_zero, x)\n",
    "\n",
    "ntaps = 19\n",
    "b_dly = frac_delay_fir(ntaps, 0.5)\n",
    "b_adv = frac_delay_fir(ntaps, -0.5)\n",
    "y2 = np.convolve(b_dly, x)\n",
    "y3 = np.convolve(b_adv, x)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y1)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "plt.plot(y3)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(b_dly)\n",
    "plt.plot(b_adv)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation-based Synchronization\n",
    "\n",
    "Use timestamp information (if available) and cross-correlation to find sample offset in recordings. This approach assumes the receiver hardware is phase and frequency coherent (i.e. sharing a common local oscillator).\n",
    "\n",
    "First some setup-work, which includes reading file headers and determining a rough offset based on recording timestamps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPI = 2 # in seconds\n",
    "\n",
    "ref_file_path = \"../data/pluto_a_ref.2021-07-27T15_24_17_598.sdriq\"\n",
    "surv_file_path = \"../data/pluto_b_surv.2021-07-27T15_24_21_819.sdriq\"\n",
    "\n",
    "_, ref_hdr = rtl_sdr_pr.ioutils.read_sdriq_samples(ref_file_path, 0, 0)\n",
    "_, surv_hdr = rtl_sdr_pr.ioutils.read_sdriq_samples(surv_file_path, 0, 0)\n",
    "\n",
    "assert ref_hdr[\"sample_rate\"] == surv_hdr[\"sample_rate\"]\n",
    "assert ref_hdr[\"center_frequency\"] == surv_hdr[\"center_frequency\"]\n",
    "\n",
    "sample_rate = ref_hdr[\"sample_rate\"]\n",
    "center_frequency = ref_hdr['center_frequency']\n",
    "num_samples_in_cpi = CPI * sample_rate\n",
    "\n",
    "print(f\"Sample rate: {sample_rate / 1e6:0.1f} MHz, Center frequency: {center_frequency / 1e6:0.1f} MHz\")\n",
    "print(f\"Start of reference channel: {ref_hdr['start_time_stamp']} -> {datetime.fromtimestamp(ref_hdr['start_time_stamp'])}\")\n",
    "print(f\"Start of surveillance channel: {surv_hdr['start_time_stamp']} -> {datetime.fromtimestamp(surv_hdr['start_time_stamp'])}\")\n",
    "\n",
    "time_diff = surv_hdr['start_time_stamp'] - ref_hdr['start_time_stamp']\n",
    "estim_sample_shift = time_diff * sample_rate\n",
    "\n",
    "print(f\"Time delta: {time_diff} sec, Estimated sample shift: {estim_sample_shift}\")\n",
    "\n",
    "ref_samples, _ = rtl_sdr_pr.ioutils.read_sdriq_samples(ref_file_path, int(num_samples_in_cpi * 2), max(0, int(estim_sample_shift - num_samples_in_cpi)))\n",
    "surv_samples, _ = rtl_sdr_pr.ioutils.read_sdriq_samples(surv_file_path, int(num_samples_in_cpi * 2), max(0, -int(estim_sample_shift - num_samples_in_cpi)))\n",
    "\n",
    "sub_sample_factor = 1\n",
    "ref_samples = ref_samples[::sub_sample_factor]\n",
    "surv_samples = surv_samples[::sub_sample_factor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now correlate and find the correlation peak.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NO_CUPY:\n",
    "    # PLEASE INSTALL CUPY! OTHERWISE THIS IS SOOO INCREADIBLY SLOW!\n",
    "    corr = np.correlate(ref_samples, surv_samples, mode=\"same\")\n",
    "else:\n",
    "    corr = cp.correlate(cp.asarray(ref_samples), cp.asarray(surv_samples), mode=\"same\").get()\n",
    "corr_mag = np.abs(corr)\n",
    "corr_mag_db = 10 * np.log10(corr_mag / np.max(corr_mag))\n",
    "\n",
    "peak_idx = np.argmax(corr_mag)\n",
    "peak_time_offset = (peak_idx - corr_mag.size / 2) / sample_rate * sub_sample_factor\n",
    "\n",
    "print(f\"Correlation peak at {peak_idx} with time offset of {peak_time_offset * 1000:0.3f} msec after initial estimation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 7))\n",
    "plt.plot(np.linspace(-corr_mag_db.size / 2 / sample_rate * 1000 * sub_sample_factor, corr_mag_db.size / 2 / sample_rate * 1000 * sub_sample_factor, corr_mag_db.size), corr_mag_db)\n",
    "plt.xlabel(\"time delta [msec]\")\n",
    "plt.ylabel(\"correlation [dB]\")\n",
    "plt.xticks(np.arange(-CPI * 1000, CPI * 1000 + 1, step=100, dtype=np.int32))\n",
    "plt.grid()\n",
    "\n",
    "plt.annotate(f\"Peak\\n\"\n",
    "             f\"sample offset: {peak_idx * sub_sample_factor}\\n\"\n",
    "             f\"time offset: {peak_time_offset * 1000:0.3f} msec\",\n",
    "             xy=(peak_time_offset * 1000, corr_mag_db[peak_idx]),\n",
    "             xytext=(-100, 30),\n",
    "             xycoords=\"data\",\n",
    "             textcoords=\"offset pixels\",\n",
    "             arrowprops={'arrowstyle': 'wedge'});"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d064f66fe564224dbd61a4a89ab4eb5098318cbedf7c1bb240b86c1a92eb320"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('rtl-sdr-pr': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
